{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment path and autheticating the OpenAI API\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your API key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speciality of the document loader with Integration is we need to specify the path of input\n",
    "# Whether websit link or path to cloud storage etc\n",
    "\n",
    "loader  =  HNLoader(\"https://news.ycombinator.com/item?id=36697119\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endisneigh 9 months ago  \n",
      "             | next [–] \n",
      "\n",
      "I wish the folks who clearly do not like Google would just not use their products instead of spamming every thread about how they will kill the product, true or not.——Anyway,It’s not clear which model they’re using for this. I assume whatever Bard is using, but who knows. This is relevant because depending on the intended experience the latency will matter.Overall it’s not a bad idea, but I do wonder what the monetization path will be for Google. I imagine this will be part of workspace. Perhaps they will add more tiers to include these offerings.I wish they shared a bit about how this will be differentiated from Bard. Is this simply a new front end to Bard? It’s really an open question. I haven’t seen many products that use LLMs that are better than the prompt response UX.The most interesting thing about this blog post is the “source grounding.” I’m curious if there’s actual engineering behind it, or is it prompt tweaking contextualized behind the scenes on a given doc.\n",
      "======================\n",
      "{'source': 'https://news.ycombinator.com/item?id=36697119', 'title': 'NotebookLM: An AI Notebook'}\n"
     ]
    }
   ],
   "source": [
    "# Visualising the data (page content and metadata)\n",
    "\n",
    "print(data[0].page_content)\n",
    "print(\"======================\")\n",
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will design the human prompt.\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"Please give me a short summary of the following HAckerNews comment:\\n {comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt =  ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(comment = data[0].page_content).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The commenter expresses frustration with people who dislike Google constantly criticizing their products. They discuss the uncertainty around the model being used for a new Google product, questioning its differentiation from Bard and speculating on potential monetization paths. They find the concept interesting, particularly the \"source grounding\" mentioned in the blog post, and wonder about the engineering behind it.' response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 243, 'total_tokens': 312}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-2f351b01-5225-40ed-a2a3-e0495e56c1fe-0'\n"
     ]
    }
   ],
   "source": [
    "result =  chat_model(request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The commenter expresses frustration with people who dislike Google constantly criticizing their products. They discuss the uncertainty around the model being used for a new Google product, questioning its differentiation from Bard and speculating on potential monetization paths. They find the concept interesting, particularly the \"source grounding\" mentioned in the blog post, and wonder about the engineering behind it.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
